You are an autonomous senior full-stack engineer + product designer + ML engineer. Build a UI-heavy full-stack app called “WardOps Digital Twin” (SimCity for hospital ops) with LLM tool-calling and a discrete-event simulation engine. You must ship a working demo that feels like a real command center.

Hard rules
- Do not ask me questions unless absolutely blocking. If something is unclear, pick a sensible default and document it.
- Prioritize a polished, interactive UI over backend perfection.
- Use synthetic data only (no real patient data). Make it realistic, not clinical. This is ops simulation, not diagnosis.
- Everything must be runnable locally with one command and deployable.
- Deliver incremental milestones with a working app at each milestone.

Goal
An interactive command center where the user can:
1) Replay a hospital unit day via a time scrubber.
2) See a floor map with beds and occupancy updating over time.
3) Explore patient flow and staffing with rich dashboards.
4) Run “what-if” scenarios using a simulation engine.
5) Use an LLM copilot that calls tools to summarize bottlenecks, convert incident notes into structured events, and generate scenario parameters.
6) Compare baseline vs scenario with a clear diff overlay.

Tech stack (use exactly this unless you have a strong reason)
Frontend
- Next.js (App Router) + TypeScript
- TailwindCSS + shadcn/ui
- Framer Motion
- Recharts for graphs
- react-flow or custom canvas/SVG for map and event graph
- WebSocket client for realtime replay updates

Backend
- FastAPI + Python
- Postgres (with pgvector) for events, state snapshots, scenarios, docs
- Redis for pub/sub and caching
- Celery or RQ for async simulation runs
- WebSockets (FastAPI) for pushing replay and simulation progress

AI
- LLM API with tool calling (function calling)
- RAG over mock hospital policy docs stored in pgvector
- Strict safety: do not provide medical advice, diagnosis, or treatment

Deliverables
1) Running application with:
   - Landing page, demo data loader, and main command center
   - Time scrubber replay
   - Scenario builder and scenario compare view
   - LLM ops copilot with tool calling and UI action buttons
2) Repo structure with clear READMEs, scripts, and env templates
3) Architecture doc: data model, API list, tool schemas, simulation approach
4) Seeded synthetic dataset generator (deterministic seed)
5) A demo script: what to click and what to say to show the product

Product requirements (UI and features)

A) Command center layout (single-page cockpit)
Layout: left map, center timeline, right dashboards and copilot, top nav
- Floor map of one unit (example: 24 beds, 2 nurse stations, corridors)
  - Beds are nodes with status: empty, occupied, cleaning, blocked, isolation
  - Hover shows patient summary
  - Click opens patient trace drawer
  - Smooth transitions when occupancy changes during replay
- Timeline scrubber
  - Zoom levels: 6h, 12h, 24h
  - Event markers: admission, transfer, discharge, imaging delay, consult, escalation, cleaning start/end
  - Play, pause, speed (1x, 2x, 5x)
- Patient flow dashboard
  - Sankey or alluvial: ED -> Unit -> ICU -> Discharge (aggregate)
  - Queue chart: ED waiting, bed wait time, imaging queue
  - KPI cards: occupancy %, average LOS, time-to-bed, SLA breaches, nurse load
- Staffing board
  - List nurses and their assignments per shift
  - Drag and drop patient to nurse (updates nurse load)
  - Show warnings: ratio exceeded, high acuity overload
- Ops copilot panel
  - Chat UI with citations when using policies
  - Buttons for suggested actions: “Run sim”, “Pin chart”, “Open diff”, “Create scenario”
  - It must call tools, not hallucinate state

B) Patient trace view
When selecting a patient:
- Event list on a mini timeline
- “Journey graph” view: nodes for events, edges for cause or sequence
- Metrics: total wait time, number of handoffs, delays
- Handoff summary generated by LLM (ops focused)

C) Scenario builder
User can create scenarios by:
- UI sliders and toggles:
  - Arrival multiplier (0.5x to 2.0x)
  - Acuity mix shift (low/med/high)
  - Beds open/closed
  - Staffing changes (add/remove nurse per shift)
  - Transport capacity
  - Imaging capacity
- Natural language prompt box:
  - “Flu surge for 6 hours, add 2 nurses, reduce imaging capacity by 20 percent”
  - LLM converts to parameters via a tool and shows an editable summary

D) Simulation engine
Build a discrete-event simulation (DES) with:
- Entities: patient, bed, nurse, resource (imaging, transport)
- Events: arrival, triage, admission request, bed assignment, transfer, imaging request, imaging start/end, cleaning start/end, discharge
- Constraints:
  - Bed availability by type
  - Nurse staffing ratios and shift coverage
  - Resource queues (imaging, transport)
- Outputs:
  - Time series: occupancy, queues, nurse load
  - Per-patient outcomes: wait times, SLA breach flags, transfers
  - Bottleneck attribution: which constraint caused delay

E) Scenario compare and diff overlay
- Choose baseline and scenario run
- Show:
  - KPI delta table (absolute + percent)
  - Overlay charts: baseline vs scenario
  - Map overlay: highlight beds or time windows with biggest congestion
  - “Explain the delta” narrative generated by LLM using simulation outputs, with citations to policy docs when relevant

Synthetic data requirements
- Generator produces:
  - A 24 hour day, minute resolution events
  - 200 to 600 patient arrivals depending on settings
  - Realistic distributions (LOS, acuity, imaging probability)
  - Random but deterministic with a seed
- Also produce a few mock policy docs (markdown or PDF) for RAG:
  - isolation protocol
  - nurse ratio guidelines
  - transport SLA
  - imaging priority rules
- Store docs and embeddings in pgvector

LLM tool calling requirements

Define tools with JSON schemas and implement them on backend.

Minimum tools:
1) query_state(time_iso, unit_id) -> current occupancy, queues, staffing summary
2) get_patient_trace(patient_id) -> events + metrics
3) summarize_bottlenecks(time_range, scenario_id) -> top bottlenecks with supporting stats
4) run_simulation(params, baseline_id_optional) -> job_id
5) get_simulation_status(job_id) -> progress, partial outputs
6) get_simulation_results(scenario_id) -> outputs for dashboards
7) parse_incident_note(note_text) -> structured events (type, timestamp, entities, confidence)
8) propose_scenario_from_text(text) -> normalized scenario params with reasoning
9) retrieve_policy_snippets(query, k) -> doc snippets + sources for citations

Copilot behavior rules:
- Must always call query_state before making operational claims about “now”
- Must cite policies when referencing rules
- Must refuse medical advice requests and redirect to ops framing
- Must output action objects that the frontend can render as buttons

Data model (Postgres)

Implement tables (or equivalent) for:
- units, beds, nurses, shifts
- patients (synthetic)
- events (normalized)
- state_snapshots (optional, for fast replay)
- scenarios (baseline and variants)
- simulation_runs (status, metrics jsonb, timeseries jsonb)
- policy_docs (content, metadata)
- policy_embeddings (vector, doc_id, chunk_text)

APIs (FastAPI)

Provide:
- REST endpoints for loading demo data, listing scenarios, fetching results, fetching patient traces
- WebSocket endpoint for replay stream (time ticks + deltas)
- WebSocket or polling for simulation job progress
- LLM tool endpoints (used by the tool router)

Frontend screens
1) / (Landing)
- Button: “Load demo dataset”
- Button: “Go to Command Center”
2) /command
- Cockpit layout with map, timeline, dashboards, copilot
3) /scenario
- Scenario builder + run + results preview
4) /compare
- Scenario compare and diff overlay
5) /patient/[id]
- Patient trace view (also accessible as drawer from command)

UX polish requirements
- Smooth animations for map occupancy and timeline playback
- Skeleton loaders for data fetches
- Command palette (Cmd-K) for navigation and actions
- Dark mode
- Keyboard shortcuts for play/pause, step forward/back, open search
- Visual hierarchy: KPI cards, alerts, and bottlenecks must pop

Performance requirements
- Replay must feel realtime and not lag for a 24 hour dataset
- Use delta updates over WebSocket, not full refresh each tick
- Cache heavy results and precompute aggregates

Testing and safety
- Unit tests for simulation engine and data generator
- Basic integration tests for API endpoints
- LLM safety: hard refusal patterns for medical requests
- Security basics: input validation, rate limit LLM endpoints, no secrets in frontend

Deployment
- Provide docker-compose with services:
  - frontend, backend, postgres, redis, worker
- One-command run:
  - docker compose up --build
- Provide a simple cloud deploy path (Render/Fly.io) with notes

Milestones

Milestone 1: Foundation
- Repo scaffolding, docker-compose, DB migrations
- Seeded synthetic generator writes to DB
- Basic REST endpoints
- Minimal UI that can load and show a static map and event list

Milestone 2: Replay
- Timeline scrubber, play/pause/speed
- WebSocket replay stream with deltas
- Map updates over time
- Basic KPI cards

Milestone 3: Dashboards
- Sankey or flow view
- Queue charts, nurse load chart
- Patient trace drawer

Milestone 4: Simulation
- Scenario builder UI
- Async simulation runs
- Results stored and visualized

Milestone 5: Compare
- Baseline vs scenario compare view
- Diff overlay, KPI delta, narrative explanation

Milestone 6: LLM Copilot
- Tool schemas and tool router
- Copilot UI with action buttons
- Incident note parser and scenario-from-text
- RAG over policy docs with citations

Milestone 7: Polish
- Command palette, keyboard shortcuts, dark mode
- Improved animations and loading states
- Demo script and final docs

Acceptance criteria (definition of done)
- I can load demo data, replay a day, inspect a patient, create a scenario, run simulation, compare results, and ask the copilot to summarize bottlenecks and generate a scenario from text.
- The UI feels like a real command center and is clearly the main value.
- The copilot uses tools and citations, not vibes.
- Everything runs locally with docker-compose.

Output format you must produce as the agent
- A project plan checklist with milestones and tasks
- Then implement the code in the repo
- Provide brief “how to run” steps
- Provide a demo walkthrough script
- Provide a short postmortem: tradeoffs and future improvements
